{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from mnist_loader import mnist_data\n",
    "from adaboost import Booster\n",
    "from haar_features import HaarFeatureMaker\n",
    "\n",
    "\n",
    "data = mnist_data()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code to for the generator\n",
    "\n",
    "Here we define the generator object, and also the code to train the generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GenerativeNet, self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 784\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# Noise\n",
    "def noise(size):\n",
    "    n = torch.randn(size, 100)\n",
    "    if torch.cuda.is_available(): return n.cuda \n",
    "    return n\n",
    "\n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "\n",
    "def train_generator(optimizer, fake_data, oracle_function):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = oracle_function(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    target = torch.ones(fake_data.size(0), 1)\n",
    "    error = loss(prediction, target)\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator oracle\n",
    "\n",
    "Here we define the discriminator oracle function. The main object of interest is the Booster() class, which implements the adaboost algorithm on haar features. The adabooster has a function which generates a tensor object that can be used as the final discriminator in torch format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "haars = HaarFeatureMaker(28)\n",
    "\n",
    "def discriminator_oracle(real_data, fake_data):\n",
    "    X = np.vstack((real_data,fake_data))\n",
    "    Y = np.zeros((X.shape[0],))\n",
    "    num_real = real_data.shape[0]\n",
    "    Y[:num_real] = 1.\n",
    "    boosting = Booster(X,Y,haars)\n",
    "    boosting.train(5)\n",
    "    predictor = boosting._group_hypothesis.get_tensor\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_batch_size = 100\n",
    "discriminator_batch_size = 10\n",
    "data_loader_gen = torch.utils.data.DataLoader(data, batch_size=generator_batch_size, shuffle=True)\n",
    "data_loader_dis = torch.utils.data.DataLoader(data, batch_size=discriminator_batch_size, shuffle=True)\n",
    "\n",
    "# Create a generator\n",
    "generator = GenerativeNet()\n",
    "\n",
    "# Optimizer for generator\n",
    "g_optimizer = Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# We start by grabbing batches of data:\n",
    "for epoch,(real_discrim_batch,_)  in enumerate(data_loader_dis):\n",
    "    \n",
    "    # Seems to be some problem with the size being [N, 1, 28, 28], need to conver to [N, 28, 28]\n",
    "    real_data_discrim = real_discrim_batch.view((real_discrim_batch.size(0), 28, 28)).numpy()\n",
    "    \n",
    "    # Generate some fake data:\n",
    "    fake_data_discrim = generator(noise(real_discrim_batch.size(0))).detach().numpy()\n",
    "    \n",
    "    # This thing returns a vector, but my boosting alg requires 28x28 images:\n",
    "    fake_data_discrim = fake_data_discrim.reshape((-1,28,28))\n",
    "    \n",
    "    # Train the boosting algorithm    \n",
    "    oracle_predictor = discriminator_oracle(real_data_discrim, fake_data_discrim)\n",
    "    \n",
    "    # Now we train the generator according to the function received from oracle\n",
    "    for n_batch, (real_batch,_) in enumerate(data_loader_gen):\n",
    "\n",
    "        fake_data = generator(noise(real_batch.size(0)))\n",
    "        g_error = train_generator(g_optimizer, fake_data, oracle_predictor)\n",
    "\n",
    "\n",
    "    # Display Progress\n",
    "    if (n_batch) % 100 == 0:\n",
    "        continue\n",
    "#         display.clear_output(True)\n",
    "        # Display Images\n",
    "#         test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
    "\n",
    "    # Model Checkpoints\n",
    "#     logger.save_models(generator, discriminator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
